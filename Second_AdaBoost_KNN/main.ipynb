{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 0.6 [ True  True  True False False False  True  True  True False]\n",
      "1 0.5 0.5 [False  True  True False False False  True  True  True False]\n",
      "1 1.0 0.5 [False  True  True False False False  True  True  True False]\n",
      "1 1.5 0.4 [False False  True False False False  True  True  True False]\n",
      "1 2.0 0.4 [False False  True False False False  True  True  True False]\n",
      "1 2.5 0.30000000000000004 [False False False False False False  True  True  True False]\n",
      "1 3.0 0.30000000000000004 [False False False False False False  True  True  True False]\n",
      "1 3.5 0.4 [False False False  True False False  True  True  True False]\n",
      "1 4.0 0.4 [False False False  True False False  True  True  True False]\n",
      "1 4.5 0.5 [False False False  True  True False  True  True  True False]\n",
      "1 5.0 0.5 [False False False  True  True False  True  True  True False]\n",
      "1 5.5 0.6 [False False False  True  True  True  True  True  True False]\n",
      "1 6.0 0.6 [False False False  True  True  True  True  True  True False]\n",
      "1 6.5 0.5 [False False False  True  True  True False  True  True False]\n",
      "1 7.0 0.5 [False False False  True  True  True False  True  True False]\n",
      "1 7.5 0.4 [False False False  True  True  True False False  True False]\n",
      "1 8.0 0.4 [False False False  True  True  True False False  True False]\n",
      "1 8.5 0.30000000000000004 [False False False  True  True  True False False False False]\n",
      "1 9.0 0.30000000000000004 [False False False  True  True  True False False False False]\n",
      "2.5 0.30000000000000004\n",
      "2 0 0.7142857142857142 [ True  True  True False False False  True  True  True False]\n",
      "2 0.5 0.6428571428571428 [False  True  True False False False  True  True  True False]\n",
      "2 1.0 0.6428571428571428 [False  True  True False False False  True  True  True False]\n",
      "2 1.5 0.5714285714285713 [False False  True False False False  True  True  True False]\n",
      "2 2.0 0.5714285714285713 [False False  True False False False  True  True  True False]\n",
      "2 2.5 0.4999999999999999 [False False False False False False  True  True  True False]\n",
      "2 3.0 0.4999999999999999 [False False False False False False  True  True  True False]\n",
      "2 3.5 0.5714285714285713 [False False False  True False False  True  True  True False]\n",
      "2 4.0 0.5714285714285713 [False False False  True False False  True  True  True False]\n",
      "2 4.5 0.6428571428571427 [False False False  True  True False  True  True  True False]\n",
      "2 5.0 0.6428571428571427 [False False False  True  True False  True  True  True False]\n",
      "2 5.5 0.7142857142857142 [False False False  True  True  True  True  True  True False]\n",
      "2 6.0 0.7142857142857142 [False False False  True  True  True  True  True  True False]\n",
      "2 6.5 0.5476190476190476 [False False False  True  True  True False  True  True False]\n",
      "2 7.0 0.5476190476190476 [False False False  True  True  True False  True  True False]\n",
      "2 7.5 0.38095238095238093 [False False False  True  True  True False False  True False]\n",
      "2 8.0 0.38095238095238093 [False False False  True  True  True False False  True False]\n",
      "2 8.5 0.21428571428571427 [False False False  True  True  True False False False False]\n",
      "2 9.0 0.21428571428571427 [False False False  True  True  True False False False False]\n",
      "8.5 0.21428571428571427\n",
      "3 0 0.4545454545454546 [ True  True  True False False False  True  True  True False]\n",
      "3 0.5 0.4090909090909091 [False  True  True False False False  True  True  True False]\n",
      "3 1.0 0.4090909090909091 [False  True  True False False False  True  True  True False]\n",
      "3 1.5 0.36363636363636365 [False False  True False False False  True  True  True False]\n",
      "3 2.0 0.36363636363636365 [False False  True False False False  True  True  True False]\n",
      "3 2.5 0.3181818181818182 [False False False False False False  True  True  True False]\n",
      "3 3.0 0.3181818181818182 [False False False False False False  True  True  True False]\n",
      "3 3.5 0.48484848484848486 [False False False  True False False  True  True  True False]\n",
      "3 4.0 0.48484848484848486 [False False False  True False False  True  True  True False]\n",
      "3 4.5 0.6515151515151515 [False False False  True  True False  True  True  True False]\n",
      "3 5.0 0.6515151515151515 [False False False  True  True False  True  True  True False]\n",
      "3 5.5 0.8181818181818182 [False False False  True  True  True  True  True  True False]\n",
      "3 6.0 0.8181818181818182 [False False False  True  True  True  True  True  True False]\n",
      "3 6.5 0.7121212121212123 [False False False  True  True  True False  True  True False]\n",
      "3 7.0 0.7121212121212123 [False False False  True  True  True False  True  True False]\n",
      "3 7.5 0.6060606060606061 [False False False  True  True  True False False  True False]\n",
      "3 8.0 0.6060606060606061 [False False False  True  True  True False False  True False]\n",
      "3 8.5 0.5 [False False False  True  True  True False False False False]\n",
      "3 9.0 0.5 [False False False  True  True  True False False False False]\n",
      "2.5 0.3181818181818182\n",
      "4 0 0.6000000000000001 [ True  True  True False False False  True  True  True False]\n",
      "4 0.5 0.5666666666666667 [False  True  True False False False  True  True  True False]\n",
      "4 1.0 0.5666666666666667 [False  True  True False False False  True  True  True False]\n",
      "4 1.5 0.5333333333333334 [False False  True False False False  True  True  True False]\n",
      "4 2.0 0.5333333333333334 [False False  True False False False  True  True  True False]\n",
      "4 2.5 0.5 [False False False False False False  True  True  True False]\n",
      "4 3.0 0.5 [False False False False False False  True  True  True False]\n",
      "4 3.5 0.6222222222222222 [False False False  True False False  True  True  True False]\n",
      "4 4.0 0.6222222222222222 [False False False  True False False  True  True  True False]\n",
      "4 4.5 0.7444444444444445 [False False False  True  True False  True  True  True False]\n",
      "4 5.0 0.7444444444444445 [False False False  True  True False  True  True  True False]\n",
      "4 5.5 0.8666666666666667 [False False False  True  True  True  True  True  True False]\n",
      "4 6.0 0.8666666666666667 [False False False  True  True  True  True  True  True False]\n",
      "4 6.5 0.7000000000000002 [False False False  True  True  True False  True  True False]\n",
      "4 7.0 0.7000000000000002 [False False False  True  True  True False  True  True False]\n",
      "4 7.5 0.5333333333333334 [False False False  True  True  True False False  True False]\n",
      "4 8.0 0.5333333333333334 [False False False  True  True  True False False  True False]\n",
      "4 8.5 0.36666666666666675 [False False False  True  True  True False False False False]\n",
      "4 9.0 0.36666666666666675 [False False False  True  True  True False False False False]\n",
      "8.5 0.36666666666666675\n",
      "5 0 0.4736842105263158 [ True  True  True False False False  True  True  True False]\n",
      "5 0.5 0.4473684210526315 [False  True  True False False False  True  True  True False]\n",
      "5 1.0 0.4473684210526315 [False  True  True False False False  True  True  True False]\n",
      "5 1.5 0.42105263157894735 [False False  True False False False  True  True  True False]\n",
      "5 2.0 0.42105263157894735 [False False  True False False False  True  True  True False]\n",
      "5 2.5 0.39473684210526316 [False False False False False False  True  True  True False]\n",
      "5 3.0 0.39473684210526316 [False False False False False False  True  True  True False]\n",
      "5 3.5 0.5614035087719298 [False False False  True False False  True  True  True False]\n",
      "5 4.0 0.5614035087719298 [False False False  True False False  True  True  True False]\n",
      "5 4.5 0.7280701754385963 [False False False  True  True False  True  True  True False]\n",
      "5 5.0 0.7280701754385963 [False False False  True  True False  True  True  True False]\n",
      "5 5.5 0.8947368421052629 [False False False  True  True  True  True  True  True False]\n",
      "5 6.0 0.8947368421052629 [False False False  True  True  True  True  True  True False]\n",
      "5 6.5 0.7631578947368419 [False False False  True  True  True False  True  True False]\n",
      "5 7.0 0.7631578947368419 [False False False  True  True  True False  True  True False]\n",
      "5 7.5 0.6315789473684209 [False False False  True  True  True False False  True False]\n",
      "5 8.0 0.6315789473684209 [False False False  True  True  True False False  True False]\n",
      "5 8.5 0.4999999999999999 [False False False  True  True  True False False False False]\n",
      "5 9.0 0.4999999999999999 [False False False  True  True  True False False False False]\n",
      "2.5 0.39473684210526316\n",
      "6 0 0.5652173913043479 [ True  True  True False False False  True  True  True False]\n",
      "6 0.5 0.5434782608695653 [False  True  True False False False  True  True  True False]\n",
      "6 1.0 0.5434782608695653 [False  True  True False False False  True  True  True False]\n",
      "6 1.5 0.5217391304347827 [False False  True False False False  True  True  True False]\n",
      "6 2.0 0.5217391304347827 [False False  True False False False  True  True  True False]\n",
      "6 2.5 0.5 [False False False False False False  True  True  True False]\n",
      "6 3.0 0.5 [False False False False False False  True  True  True False]\n",
      "6 3.5 0.6376811594202899 [False False False  True False False  True  True  True False]\n",
      "6 4.0 0.6376811594202899 [False False False  True False False  True  True  True False]\n",
      "6 4.5 0.7753623188405798 [False False False  True  True False  True  True  True False]\n",
      "6 5.0 0.7753623188405798 [False False False  True  True False  True  True  True False]\n",
      "6 5.5 0.9130434782608696 [False False False  True  True  True  True  True  True False]\n",
      "6 6.0 0.9130434782608696 [False False False  True  True  True  True  True  True False]\n",
      "6 6.5 0.7463768115942029 [False False False  True  True  True False  True  True False]\n",
      "6 7.0 0.7463768115942029 [False False False  True  True  True False  True  True False]\n",
      "6 7.5 0.5797101449275363 [False False False  True  True  True False False  True False]\n",
      "6 8.0 0.5797101449275363 [False False False  True  True  True False False  True False]\n",
      "6 8.5 0.41304347826086957 [False False False  True  True  True False False False False]\n",
      "6 9.0 0.41304347826086957 [False False False  True  True  True False False False False]\n",
      "8.5 0.41304347826086957\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "samples = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "labels = np.array([1, 1, 1, -1, -1, -1, 1, 1, 1, -1])\n",
    "\n",
    "initial_threshold = 2.5\n",
    "iterations = 6\n",
    "\n",
    "weights = np.ones(len(samples)) / len(samples)\n",
    "\n",
    "weights_per_iteration = [weights.copy()]  \n",
    "alpha_per_iteration = [0]  \n",
    "thresholds_per_iteration = [initial_threshold]  \n",
    "def weak_classifier(x, theta):\n",
    "    return np.where(x < theta, 1, -1)\n",
    "\n",
    "def find_optimal_threshold(samples, labels, weights,iter):\n",
    "    min_sample, max_sample = np.min(samples), np.max(samples)\n",
    "    best_threshold = min_sample\n",
    "    min_error = float('inf')\n",
    "    \n",
    "   \n",
    "    threshold = min_sample\n",
    "    while threshold <= max_sample:\n",
    "        predictions = weak_classifier(samples, threshold)\n",
    "        misclassified = (predictions != labels)\n",
    "        error = np.sum(weights * misclassified)\n",
    "        print(iter,threshold,error,misclassified,)\n",
    "        \n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_threshold = threshold\n",
    "        \n",
    "        \n",
    "        threshold += 0.5\n",
    "    \n",
    "    print(best_threshold,min_error)\n",
    "            \n",
    "    return best_threshold, min_error\n",
    "\n",
    "\n",
    "e = []\n",
    "pred = []\n",
    "for i in range(1, iterations + 1):\n",
    "    threshold, error = find_optimal_threshold(samples, labels, weights,i)\n",
    "    thresholds_per_iteration.append(threshold)\n",
    "\n",
    "    e.append(error)\n",
    "    \n",
    "    alpha = 0.5 * np.log((1 - error) / error) \n",
    "    alpha_per_iteration.append(alpha)\n",
    "    \n",
    "    predictions = weak_classifier(samples, threshold)\n",
    "    pred.append([i,predictions]) \n",
    "    misclassified = (predictions != labels)\n",
    "    \n",
    "    for j in range(len(weights)):\n",
    "        if misclassified[j]:\n",
    "            weights[j] *= np.exp(alpha)  \n",
    "        else:\n",
    "            weights[j] *= np.exp(-alpha)  \n",
    "    \n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    \n",
    "    weights_per_iteration.append(weights.copy())\n",
    "\n",
    "\n",
    "\n",
    "weights_df = pd.DataFrame(weights_per_iteration, columns=[f\"x{i}\" for i in range(len(samples))], index=[f\"Iteration {i}\" for i in range(iterations + 1)])\n",
    "alpha_df = pd.DataFrame(alpha_per_iteration, columns=[\"Alpha\"], index=[f\"Iteration {i}\" for i in range(iterations + 1)])\n",
    "thresholds_df = pd.DataFrame(thresholds_per_iteration, columns=[\"Threshold\"], index=[f\"Iteration {i}\" for i in range(iterations + 1)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Iteration 0</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration 1</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration 2</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration 3</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration 4</th>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration 5</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.137681</td>\n",
       "      <td>0.137681</td>\n",
       "      <td>0.137681</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration 6</th>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.141975</td>\n",
       "      <td>0.141975</td>\n",
       "      <td>0.141975</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   x0        x1        x2        x3        x4        x5  \\\n",
       "Iteration 0  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000   \n",
       "Iteration 1  0.071429  0.071429  0.071429  0.071429  0.071429  0.071429   \n",
       "Iteration 2  0.045455  0.045455  0.045455  0.166667  0.166667  0.166667   \n",
       "Iteration 3  0.033333  0.033333  0.033333  0.122222  0.122222  0.122222   \n",
       "Iteration 4  0.026316  0.026316  0.026316  0.166667  0.166667  0.166667   \n",
       "Iteration 5  0.021739  0.021739  0.021739  0.137681  0.137681  0.137681   \n",
       "Iteration 6  0.018519  0.018519  0.018519  0.166667  0.166667  0.166667   \n",
       "\n",
       "                   x6        x7        x8        x9  \n",
       "Iteration 0  0.100000  0.100000  0.100000  0.100000  \n",
       "Iteration 1  0.166667  0.166667  0.166667  0.071429  \n",
       "Iteration 2  0.106061  0.106061  0.106061  0.045455  \n",
       "Iteration 3  0.166667  0.166667  0.166667  0.033333  \n",
       "Iteration 4  0.131579  0.131579  0.131579  0.026316  \n",
       "Iteration 5  0.166667  0.166667  0.166667  0.021739  \n",
       "Iteration 6  0.141975  0.141975  0.141975  0.018519  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "mat_file_path = 'test_data.mat'\n",
    "mat_data = scipy.io.loadmat(mat_file_path)\n",
    "\n",
    "data_X = mat_data['X']\n",
    "data_Y = mat_data['Y']\n",
    "\n",
    "df_X = pd.DataFrame(data_X)\n",
    "df_Y = pd.DataFrame(data_Y)\n",
    "\n",
    "df_combined = pd.concat([df_X, df_Y], axis=1)\n",
    "\n",
    "\n",
    "df_combined.columns = [f\"X{i+1}\" for i in range(df_X.shape[1])] + [f\"Y{i+1}\" for i in range(df_Y.shape[1])]\n",
    "\n",
    "\n",
    "output_csv_path = 'test.csv'\n",
    "df_combined.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "y_test = test_data['Y'].iloc[:1000].tolist()\n",
    "\n",
    "train = train_data.iloc[:6000].to_numpy()\n",
    "test = test_data.iloc[:1000].to_numpy()\n",
    "\n",
    "y_test1 = train_data['Y'].iloc[:1000].tolist()\n",
    "\n",
    "test1 = train_data.iloc[:1000].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "def euclidean_distance(sample1, sample2):\n",
    "    return np.linalg.norm(sample1[:-1] - sample2[:-1])\n",
    "\n",
    "\n",
    "\n",
    "def voting(array):\n",
    "    second_elements = [row[1] for row in array]\n",
    "    vote_counts = Counter(second_elements)\n",
    "    vote = vote_counts.most_common(1)[0][0]\n",
    "    return vote\n",
    "\n",
    "def KNN_kernel(train_d,test_d,K):\n",
    "\tdist = []\n",
    "\tdist = [[euclidean_distance(train_d[i], test_d), train_d[i][-1]] for i in range(len(train_d))]\n",
    "\tsoretd_dist = sorted(dist, key=lambda x: x[0])\n",
    "\treturn voting(soretd_dist[:K])\n",
    "\n",
    "\n",
    "K = [1, 9, 19, 29, 39, 49, 59, 69, 79, 89, 99]\n",
    "error_list = []\n",
    "\n",
    "for k in K:\n",
    "\ty_pred = []\n",
    "\tfor t in test:\n",
    "\t\ty_pred.append(KNN_kernel(train,t,k))\n",
    "\n",
    "\taccuracy = accuracy_score(y_test, y_pred)\n",
    "\terror = 1 - accuracy\n",
    "\n",
    "\tprint(error)\n",
    "\t\n",
    "\terror_list.append([k,error])\n",
    "error_list1 = []\n",
    "for k in K:\n",
    "\ty_pred = []\n",
    "\tfor t in test1:\n",
    "\t\ty_pred.append(KNN_kernel(train,t,k))\n",
    "\n",
    "\taccuracy = accuracy_score(y_test1, y_pred)\n",
    "\terror = 1 - accuracy\n",
    "\n",
    "\tprint(error)\n",
    "\t\n",
    "\terror_list1.append([k,error])\n",
    "\n",
    "\n",
    "error_list = [[1, 0.014000000000000012], [9, 0.015000000000000013], [19, 0.028000000000000025], [29, 0.03500000000000003], [39, 0.040000000000000036], [49, 0.040000000000000036], [59, 0.04600000000000004], [69, 0.049000000000000044], [79, 0.051000000000000045], [89, 0.05400000000000005], [99, 0.05300000000000005]]\n",
    "x_values = [point[0] for point in error_list]\n",
    "y_values = [point[1] for point in error_list]\n",
    "\n",
    "x_values1 = [point[0] for point in error_list1]\n",
    "y_values1 = [point[1] for point in error_list1]\n",
    "\n",
    "\n",
    "plt.plot(x_values, y_values, marker='o', linestyle='-', color='b')\n",
    "plt.plot(x_values1, y_values1, marker='o', linestyle='-', color='r')\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.savefig(\"plot.png\", dpi=300)  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
